{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fluidize-Python Interactive Demo\n",
        "\n",
        "This notebook demonstrates the fluidize-python library for managing scientific computing projects.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import the client and see where our projects will be stored:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcc1 Projects will be stored in: /Users/henrybae/.fluidize/projects\n",
            "\ud83d\udcc1 Base directory: /Users/henrybae/.fluidize\n",
            "\ud83d\ude80 Client ready in 'local' mode!\n"
          ]
        }
      ],
      "source": [
        "# Import the fluidize client - handlers auto-register!\n",
        "from fluidize.client import FluidizeClient\n",
        "from fluidize.config import FluidizeConfig\n",
        "\n",
        "# Create client and config\n",
        "client = FluidizeClient(mode=\"local\")\n",
        "config = FluidizeConfig(mode=\"local\")\n",
        "\n",
        "print(f\"\ud83d\udcc1 Projects will be stored in: {config.local_projects_path}\")\n",
        "print(f\"\ud83d\udcc1 Base directory: {config.local_base_path}\")\n",
        "print(f\"\ud83d\ude80 Client ready in '{client.mode}' mode!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating Projects\n",
        "\n",
        "Let's create some projects with different configurations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Created project 1:\n",
            "   ID: data-pipeline-2024\n",
            "   Label: Data Processing Pipeline\n",
            "   Status: active\n"
          ]
        }
      ],
      "source": [
        "# Create a comprehensive project\n",
        "project1 = client.projects.create(\n",
        "    project_id=\"data-pipeline-2024\",\n",
        "    label=\"Data Processing Pipeline\",\n",
        "    description=\"A comprehensive data processing pipeline for customer analytics\",\n",
        "    location=\"/projects/data/customer-analytics\",\n",
        "    status=\"active\",\n",
        ")\n",
        "\n",
        "print(\"\u2705 Created project 1:\")\n",
        "print(f\"   ID: {project1.id}\")\n",
        "print(f\"   Label: {project1.label}\")\n",
        "print(f\"   Status: {project1.status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Created project 2:\n",
            "   ID: quick-experiment\n",
            "   Label: Quick Experiment\n",
            "   Status: \n",
            "   Description: ''\n"
          ]
        }
      ],
      "source": [
        "# Create a minimal project\n",
        "project2 = client.projects.create(project_id=\"quick-experiment\", label=\"Quick Experiment\")\n",
        "\n",
        "print(\"\u2705 Created project 2:\")\n",
        "print(f\"   ID: {project2.id}\")\n",
        "print(f\"   Label: {project2.label}\")\n",
        "print(f\"   Status: {project2.status}\")\n",
        "print(f\"   Description: '{project2.description}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Listing Projects\n",
        "\n",
        "Let's see all the projects we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udccb Found 1 projects:\n",
            "\n",
            " 1. project-1754038373536\n",
            "     Label: SIMPLETEST\n",
            "     Status: active\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get all projects\n",
        "projects = client.projects.list()\n",
        "\n",
        "print(f\"\ud83d\udccb Found {len(projects)} projects:\")\n",
        "print()\n",
        "\n",
        "for i, project in enumerate(projects, 1):\n",
        "    print(f\"{i:2}. {project.id}\")\n",
        "    print(f\"     Label: {project.label}\")\n",
        "    print(f\"     Status: {project.status}\")\n",
        "    if project.description:\n",
        "        print(f\"     Description: {project.description[:50]}{'...' if len(project.description) > 50 else ''}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Retrieving Specific Projects\n",
        "\n",
        "Get detailed information about a specific project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcca Project Details:\n",
            "   ID: project-1754038373536\n",
            "   Label: SIMPLETEST\n",
            "   Description: \n",
            "   Status: active\n",
            "   Location: \n",
            "   Metadata Version: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Get project details\n",
        "project = client.projects.get(\"project-1754038373536\")\n",
        "\n",
        "print(\"\ud83d\udcca Project Details:\")\n",
        "print(f\"   ID: {project.id}\")\n",
        "print(f\"   Label: {project.label}\")\n",
        "print(f\"   Description: {project.description}\")\n",
        "print(f\"   Status: {project.status}\")\n",
        "print(f\"   Location: {project.location}\")\n",
        "print(f\"   Metadata Version: {project.metadata_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No start node provided, using first node: node-1754038461760\n",
            "BFS traversal starting from node 'node-1754038461760':\n",
            "  - Adding node to traversal: node-1754038461760, previous node: None\n",
            "    - Adding neighbor to queue: node-1754038465820, will follow node-1754038461760\n",
            "  - Adding node to traversal: node-1754038465820, previous node: node-1754038461760\n",
            "Nodes to run: ['node-1754038461760', 'node-1754038465820']\n",
            "Created project run folder: /Users/henrybae/.fluidize/projects/project-1754038373536/runs/run_3\n",
            "Created run environment with number: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'flow_status': 'running', 'run_number': 3}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to log node parameters: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing node node-1754038461760 in run 3\n",
            "\n",
            "=== Starting run for node: node-1754038461760 ===\n",
            "1. Preparing environment...\n",
            "\ud83d\udd27 [Environment] Processing 0 targeted files (vs exhaustive search)\n",
            "2. Executing simulation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to log node parameters: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Handling files...\n",
            "=== Run completed for node: node-1754038461760 with result: True ===\n",
            "\n",
            "Executing node node-1754038465820 in run 3\n",
            "\n",
            "=== Starting run for node: node-1754038465820 ===\n",
            "1. Preparing environment...\n",
            "\ud83d\udd27 [Environment] Processing 0 targeted files (vs exhaustive search)\n",
            "2. Executing simulation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No active MLFlow run to log metrics to\n",
            "No active MLFlow run to log tags to\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Handling files...\n",
            "=== Run completed for node: node-1754038465820 with result: True ===\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from fluidize.core.types.runs import RunFlowPayload\n",
        "\n",
        "payload = RunFlowPayload(\n",
        "    name=\"simulation-run-1\", description=\"Running simulation flow\", tags=[\"simulation\", \"analysis\"]\n",
        ")\n",
        "\n",
        "\n",
        "project.runs.run_flow(payload)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Updating Projects\n",
        "\n",
        "Modify existing projects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Updated project:\n",
            "   ID: quick-experiment\n",
            "   Label: Quick Experiment\n",
            "   Status: in-progress\n",
            "   Description: Testing various ML algorithms for classification\n",
            "   Location: /experiments/ml/classification\n"
          ]
        }
      ],
      "source": [
        "# Update project status and description\n",
        "updated_project = client.projects.update(\n",
        "    project_id=\"quick-experiment\",\n",
        "    status=\"in-progress\",\n",
        "    description=\"Testing various ML algorithms for classification\",\n",
        "    location=\"/experiments/ml/classification\",\n",
        ")\n",
        "\n",
        "print(\"\u2705 Updated project:\")\n",
        "print(f\"   ID: {updated_project.id}\")\n",
        "print(f\"   Label: {updated_project.label}\")\n",
        "print(f\"   Status: {updated_project.status}\")\n",
        "print(f\"   Description: {updated_project.description}\")\n",
        "print(f\"   Location: {updated_project.location}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Working with Project Files\n",
        "\n",
        "Let's explore the actual files created on disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcc1 Project directory: /Users/henrybae/.fluidize/projects/data-pipeline-2024\n",
            "\ud83d\udcc1 Directory exists: True\n",
            "\n",
            "\ud83d\udcc4 Files in project:\n",
            "   - parameters.json (40 bytes)\n",
            "   - metadata.yaml (236 bytes)\n",
            "   - graph.json (32 bytes)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "import yaml\n",
        "\n",
        "# Get project directory\n",
        "project_dir = config.local_projects_path / \"data-pipeline-2024\"\n",
        "print(f\"\ud83d\udcc1 Project directory: {project_dir}\")\n",
        "print(f\"\ud83d\udcc1 Directory exists: {project_dir.exists()}\")\n",
        "print()\n",
        "\n",
        "# List files in project\n",
        "if project_dir.exists():\n",
        "    print(\"\ud83d\udcc4 Files in project:\")\n",
        "    for file in project_dir.iterdir():\n",
        "        print(f\"   - {file.name} ({file.stat().st_size} bytes)\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udccb Project Metadata:\n",
            "{\n",
            "  \"project\": {\n",
            "    \"description\": \"A comprehensive data processing pipeline for customer analytics\",\n",
            "    \"id\": \"data-pipeline-2024\",\n",
            "    \"label\": \"Data Processing Pipeline\",\n",
            "    \"location\": \"/projects/data/customer-analytics\",\n",
            "    \"metadata_version\": \"1.0\",\n",
            "    \"status\": \"active\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read and display metadata file\n",
        "metadata_file = project_dir / \"metadata.yaml\"\n",
        "if metadata_file.exists():\n",
        "    with open(metadata_file) as f:\n",
        "        metadata = yaml.safe_load(f)\n",
        "\n",
        "    print(\"\ud83d\udccb Project Metadata:\")\n",
        "    print(json.dumps(metadata, indent=2))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd17 Graph Structure:\n",
            "{\n",
            "  \"nodes\": [],\n",
            "  \"edges\": []\n",
            "}\n",
            "\n",
            "\u2699\ufe0f  Parameters:\n",
            "{\n",
            "  \"metadata\": {},\n",
            "  \"parameters\": {}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Read graph and parameters files\n",
        "graph_file = project_dir / \"graph.json\"\n",
        "params_file = project_dir / \"parameters.json\"\n",
        "\n",
        "if graph_file.exists():\n",
        "    with open(graph_file) as f:\n",
        "        graph_data = json.load(f)\n",
        "    print(\"\ud83d\udd17 Graph Structure:\")\n",
        "    print(json.dumps(graph_data, indent=2))\n",
        "    print()\n",
        "\n",
        "if params_file.exists():\n",
        "    with open(params_file) as f:\n",
        "        params_data = json.load(f)\n",
        "    print(\"\u2699\ufe0f  Parameters:\")\n",
        "    print(json.dumps(params_data, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Error Handling\n",
        "\n",
        "Let's test error handling for non-existent projects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u274c Project 'non-existent-project' not found (expected behavior)\n"
          ]
        }
      ],
      "source": [
        "# Try to get a non-existent project\n",
        "try:\n",
        "    missing_project = client.projects.get(\"non-existent-project\")\n",
        "    print(f\"Found project: {missing_project.id}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"\u274c Project 'non-existent-project' not found (expected behavior)\")\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Unexpected error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Batch Operations\n",
        "\n",
        "Create multiple projects and work with them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Created: ml-model-training - ML Model Training\n",
            "\u2705 Created: data-preprocessing - Data Preprocessing\n",
            "\u2705 Created: model-evaluation - Model Evaluation\n",
            "\n",
            "\ud83d\udcca Created 3 test projects\n"
          ]
        }
      ],
      "source": [
        "# Create multiple test projects\n",
        "test_projects = [\n",
        "    {\n",
        "        \"project_id\": \"ml-model-training\",\n",
        "        \"label\": \"ML Model Training\",\n",
        "        \"description\": \"Training deep learning models for image classification\",\n",
        "        \"status\": \"training\",\n",
        "    },\n",
        "    {\n",
        "        \"project_id\": \"data-preprocessing\",\n",
        "        \"label\": \"Data Preprocessing\",\n",
        "        \"description\": \"Cleaning and preparing raw data for analysis\",\n",
        "        \"status\": \"active\",\n",
        "    },\n",
        "    {\n",
        "        \"project_id\": \"model-evaluation\",\n",
        "        \"label\": \"Model Evaluation\",\n",
        "        \"description\": \"Evaluating and comparing different model performances\",\n",
        "        \"status\": \"pending\",\n",
        "    },\n",
        "]\n",
        "\n",
        "created_projects = []\n",
        "for project_data in test_projects:\n",
        "    project = client.projects.create(**project_data)\n",
        "    created_projects.append(project)\n",
        "    print(f\"\u2705 Created: {project.id} - {project.label}\")\n",
        "\n",
        "print(f\"\\n\ud83d\udcca Created {len(created_projects)} test projects\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcca Projects by Status:\n",
            "\n",
            "\ud83c\udff7\ufe0f  IN-PROGRESS: 1 projects\n",
            "   - quick-experiment: Quick Experiment\n",
            "\n",
            "\ud83c\udff7\ufe0f  PENDING: 1 projects\n",
            "   - model-evaluation: Model Evaluation\n",
            "\n",
            "\ud83c\udff7\ufe0f  ACTIVE: 2 projects\n",
            "   - data-pipeline-2024: Data Processing Pipeline\n",
            "   - data-preprocessing: Data Preprocessing\n",
            "\n",
            "\ud83c\udff7\ufe0f  TRAINING: 1 projects\n",
            "   - ml-model-training: ML Model Training\n"
          ]
        }
      ],
      "source": [
        "# Filter projects by status\n",
        "all_projects = client.projects.list()\n",
        "\n",
        "# Group by status\n",
        "by_status = {}\n",
        "for project in all_projects:\n",
        "    status = project.status or \"unknown\"\n",
        "    if status not in by_status:\n",
        "        by_status[status] = []\n",
        "    by_status[status].append(project)\n",
        "\n",
        "print(\"\ud83d\udcca Projects by Status:\")\n",
        "for status, projects in by_status.items():\n",
        "    print(f\"\\n\ud83c\udff7\ufe0f  {status.upper()}: {len(projects)} projects\")\n",
        "    for project in projects:\n",
        "        print(f\"   - {project.id}: {project.label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cleanup (Optional)\n",
        "\n",
        "Delete test projects if needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udca1 Uncomment the code above to delete test projects\n"
          ]
        }
      ],
      "source": [
        "# Uncomment and run this cell if you want to clean up test projects\n",
        "\n",
        "# test_project_ids = [\"ml-model-training\", \"data-preprocessing\", \"model-evaluation\"]\n",
        "\n",
        "# for project_id in test_project_ids:\n",
        "#     try:\n",
        "#         client.projects.delete(project_id)\n",
        "#         print(f\"\ud83d\uddd1\ufe0f Deleted: {project_id}\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"\u274c Project {project_id} not found\")\n",
        "\n",
        "print(\"\ud83d\udca1 Uncomment the code above to delete test projects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Working with Project Graphs\n",
        "\n",
        "Now let's explore the new graph functionality integrated with projects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcca Working with project: Data Processing Pipeline\n",
            "\ud83d\udd17 Graph access: <fluidize.managers.project_graph.ProjectGraph object at 0x10a2d0990>\n",
            "\n",
            "\ud83d\udcc8 Initial graph state:\n",
            "   Nodes: 0\n",
            "   Edges: 0\n"
          ]
        }
      ],
      "source": [
        "# Import graph types\n",
        "from fluidize.core.types.graph import GraphEdge, GraphNode, Position, graphNodeData\n",
        "\n",
        "# Get our test project\n",
        "project = client.projects.get(\"data-pipeline-2024\")\n",
        "\n",
        "print(f\"\ud83d\udcca Working with project: {project.label}\")\n",
        "print(f\"\ud83d\udd17 Graph access: {project.graph}\")\n",
        "\n",
        "# Get the current graph (should be empty initially)\n",
        "graph_data = project.graph.get()\n",
        "print(\"\\n\ud83d\udcc8 Initial graph state:\")\n",
        "print(f\"   Nodes: {len(graph_data.nodes)}\")\n",
        "print(f\"   Edges: {len(graph_data.edges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd39 Adding nodes to project graph:\n",
            "Warning: Could not copy simulation template: [Errno 2] No such file or directory: '/Users/henrybae/.fluidize/simulations/data-ingest-v1'\n",
            "   \u2705 Added: Data Ingestion\n",
            "Warning: Could not copy simulation template: [Errno 2] No such file or directory: '/Users/henrybae/.fluidize/simulations/data-clean-v1'\n",
            "   \u2705 Added: Data Cleaning\n",
            "Warning: Could not copy simulation template: [Errno 2] No such file or directory: '/Users/henrybae/.fluidize/simulations/feature-eng-v1'\n",
            "   \u2705 Added: Feature Engineering\n",
            "\n",
            "\ud83d\udcc8 Updated graph state:\n",
            "   Nodes: 3\n",
            "   - data-ingestion-001: Data Ingestion (data-source)\n",
            "   - data-cleaning-001: Data Cleaning (processor)\n",
            "   - feature-engineering-001: Feature Engineering (processor)\n"
          ]
        }
      ],
      "source": [
        "# Create some nodes for our data pipeline\n",
        "node1_data = graphNodeData(\n",
        "    label=\"Data Ingestion\", simulation_id=\"data-ingest-v1\", description=\"Load raw data from various sources\"\n",
        ")\n",
        "node1 = GraphNode(id=\"data-ingestion-001\", position=Position(x=100.0, y=100.0), data=node1_data, type=\"data-source\")\n",
        "\n",
        "node2_data = graphNodeData(\n",
        "    label=\"Data Cleaning\", simulation_id=\"data-clean-v1\", description=\"Clean and validate data quality\"\n",
        ")\n",
        "node2 = GraphNode(id=\"data-cleaning-001\", position=Position(x=300.0, y=100.0), data=node2_data, type=\"processor\")\n",
        "\n",
        "node3_data = graphNodeData(\n",
        "    label=\"Feature Engineering\", simulation_id=\"feature-eng-v1\", description=\"Extract and transform features\"\n",
        ")\n",
        "node3 = GraphNode(id=\"feature-engineering-001\", position=Position(x=500.0, y=100.0), data=node3_data, type=\"processor\")\n",
        "\n",
        "# Add nodes to the project graph\n",
        "print(\"\ud83d\udd39 Adding nodes to project graph:\")\n",
        "project.graph.add_node(node1)\n",
        "print(f\"   \u2705 Added: {node1.data.label}\")\n",
        "\n",
        "project.graph.add_node(node2)\n",
        "print(f\"   \u2705 Added: {node2.data.label}\")\n",
        "\n",
        "project.graph.add_node(node3)\n",
        "print(f\"   \u2705 Added: {node3.data.label}\")\n",
        "\n",
        "# Check updated graph\n",
        "graph_data = project.graph.get()\n",
        "print(\"\\n\ud83d\udcc8 Updated graph state:\")\n",
        "print(f\"   Nodes: {len(graph_data.nodes)}\")\n",
        "for node in graph_data.nodes:\n",
        "    print(f\"   - {node.id}: {node.data.label} ({node.type})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create edges to connect the pipeline nodes\n",
        "edge1 = GraphEdge(id=\"ingest-to-clean\", source=\"data-ingestion-001\", target=\"data-cleaning-001\", type=\"data-flow\")\n",
        "\n",
        "edge2 = GraphEdge(id=\"clean-to-feature\", source=\"data-cleaning-001\", target=\"feature-engineering-001\", type=\"data-flow\")\n",
        "\n",
        "# Add edges to connect the workflow\n",
        "print(\"\ud83d\udd17 Adding edges to create workflow:\")\n",
        "project.graph.add_edge(edge1)\n",
        "print(\"   \u2705 Connected: Data Ingestion \u2192 Data Cleaning\")\n",
        "\n",
        "project.graph.add_edge(edge2)\n",
        "print(\"   \u2705 Connected: Data Cleaning \u2192 Feature Engineering\")\n",
        "\n",
        "# Check final graph state\n",
        "graph_data = project.graph.get()\n",
        "print(\"\\n\ud83d\udcca Final pipeline graph:\")\n",
        "print(f\"   Nodes: {len(graph_data.nodes)}\")\n",
        "print(f\"   Edges: {len(graph_data.edges)}\")\n",
        "\n",
        "print(\"\\n\ud83d\udd17 Workflow connections:\")\n",
        "for edge in graph_data.edges:\n",
        "    source_node = next(n for n in graph_data.nodes if n.id == edge.source)\n",
        "    target_node = next(n for n in graph_data.nodes if n.id == edge.target)\n",
        "    print(f\"   {source_node.data.label} \u2192 {target_node.data.label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Graph Operations\n",
        "\n",
        "Let's demonstrate updating and managing the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update node position\n",
        "updated_node = GraphNode(\n",
        "    id=\"feature-engineering-001\",\n",
        "    position=Position(x=500.0, y=200.0),  # Move it down\n",
        "    data=node3_data,\n",
        "    type=\"processor\",\n",
        ")\n",
        "\n",
        "print(\"\ud83d\udccd Updating node position:\")\n",
        "result = project.graph.update_node_position(updated_node)\n",
        "print(f\"   \u2705 Moved {result.data.label} to ({result.position.x}, {result.position.y})\")\n",
        "\n",
        "# Demonstrate deletion (we'll add the node back)\n",
        "print(\"\\n\ud83d\uddd1\ufe0f Demonstrating node deletion:\")\n",
        "original_graph = project.graph.get()\n",
        "print(f\"   Before deletion: {len(original_graph.nodes)} nodes, {len(original_graph.edges)} edges\")\n",
        "\n",
        "project.graph.delete_node(\"feature-engineering-001\")\n",
        "after_deletion = project.graph.get()\n",
        "print(f\"   After deletion: {len(after_deletion.nodes)} nodes, {len(after_deletion.edges)} edges\")\n",
        "print(\"   \u26a0\ufe0f Note: Connected edges are automatically removed!\")\n",
        "\n",
        "# Add the node back\n",
        "print(\"\\n\ud83d\udd04 Adding node back:\")\n",
        "project.graph.add_node(node3)\n",
        "restored_graph = project.graph.get()\n",
        "print(f\"   After restore: {len(restored_graph.nodes)} nodes, {len(restored_graph.edges)} edges\")\n",
        "print(\"   \u26a0\ufe0f Note: Need to manually reconnect edges!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Graph Isolation & Persistence\n",
        "\n",
        "Demonstrate that graphs are isolated per project and persist to disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get another project to show isolation\n",
        "experiment_project = client.projects.get(\"quick-experiment\")\n",
        "\n",
        "print(\"\ud83d\udd2c Working with different project:\")\n",
        "print(f\"   Project 1: {project.label} - {len(project.graph.get().nodes)} nodes\")\n",
        "print(f\"   Project 2: {experiment_project.label} - {len(experiment_project.graph.get().nodes)} nodes\")\n",
        "\n",
        "# Add a node to the experiment project\n",
        "experiment_node = GraphNode(\n",
        "    id=\"experiment-node-001\",\n",
        "    position=Position(x=0.0, y=0.0),\n",
        "    data=graphNodeData(\n",
        "        label=\"ML Model Training\", simulation_id=\"ml-train-v1\", description=\"Training a neural network model\"\n",
        "    ),\n",
        "    type=\"ml-model\",\n",
        ")\n",
        "\n",
        "experiment_project.graph.add_node(experiment_node)\n",
        "\n",
        "print(\"\\n\ud83d\udcca After adding node to experiment project:\")\n",
        "print(f\"   Project 1: {project.label} - {len(project.graph.get().nodes)} nodes\")\n",
        "print(f\"   Project 2: {experiment_project.label} - {len(experiment_project.graph.get().nodes)} nodes\")\n",
        "print(\"   \u2705 Graphs are completely isolated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check graph persistence on disk\n",
        "import json\n",
        "\n",
        "project_dir = config.local_projects_path / \"data-pipeline-2024\"\n",
        "graph_file = project_dir / \"graph.json\"\n",
        "\n",
        "print(\"\ud83d\udcbe Graph persistence on disk:\")\n",
        "print(f\"   Graph file: {graph_file}\")\n",
        "print(f\"   File exists: {graph_file.exists()}\")\n",
        "\n",
        "if graph_file.exists():\n",
        "    with open(graph_file) as f:\n",
        "        graph_json = json.load(f)\n",
        "\n",
        "    print(\"   \ud83d\udcc4 Graph file contents:\")\n",
        "    print(f\"      Nodes in file: {len(graph_json.get('nodes', []))}\")\n",
        "    print(f\"      Edges in file: {len(graph_json.get('edges', []))}\")\n",
        "\n",
        "    if graph_json.get(\"nodes\"):\n",
        "        print(\"      Node examples:\")\n",
        "        for node in graph_json[\"nodes\"][:2]:  # Show first 2 nodes\n",
        "            print(f\"        - {node.get('id', 'unknown')}: {node.get('data', {}).get('label', 'no label')}\")\n",
        "\n",
        "print(\"\\n\ud83d\udd04 Graph data matches in-memory state:\")\n",
        "current_graph = project.graph.get()\n",
        "print(f\"   In-memory nodes: {len(current_graph.nodes)}\")\n",
        "print(f\"   In-memory edges: {len(current_graph.edges)}\")\n",
        "print(\"   \u2705 Data is automatically persisted to disk!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Your Experiments\n",
        "\n",
        "Use the cells below for your own experiments with projects and graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here - experiment with the fluidize client!\n",
        "# Try creating your own projects and building graphs:\n",
        "#\n",
        "# project = client.projects.create(project_id=\"my-experiment\", label=\"My Experiment\")\n",
        "# node = GraphNode(\n",
        "#     id=\"my-node\",\n",
        "#     position=Position(x=100.0, y=100.0),\n",
        "#     data=graphNodeData(label=\"My Node\", simulation_id=\"my-sim\"),\n",
        "#     type=\"custom\"\n",
        "# )\n",
        "# project.graph.add_node(node)\n",
        "#\n",
        "# Explore the API!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More experimentation space - try advanced graph operations:\n",
        "#\n",
        "# # Build complex workflows\n",
        "# # Update node positions\n",
        "# # Connect multiple projects\n",
        "# # Test error handling\n",
        "#\n",
        "# print(\"Ready for your experiments!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated the complete fluidize-python API:\n",
        "\n",
        "### \u2705 **Project Management**\n",
        "- **Simple Import** - Just `from fluidize.client import FluidizeClient`  \n",
        "- **Project CRUD Operations** - Create, Read, Update, Delete  \n",
        "- **File System Integration** - Projects stored in `~/.fluidize/projects/`  \n",
        "- **Error Handling** - Proper exceptions for missing projects  \n",
        "- **Batch Operations** - Working with multiple projects  \n",
        "\n",
        "### \u2705 **New Graph Integration** \n",
        "- **Intuitive API** - `project.graph.add_node(node)` instead of complex backend calls\n",
        "- **Project Scoping** - All graph operations automatically scoped to project\n",
        "- **Node & Edge Operations** - Add, update, delete nodes and edges\n",
        "- **Graph Persistence** - Automatic saving to `graph.json` \n",
        "- **Cross-Project Isolation** - Each project has its own independent graph\n",
        "- **Position Management** - Update node positions with `update_node_position()`\n",
        "- **Smart Edge Cleanup** - Deleting nodes automatically removes connected edges\n",
        "\n",
        "### \u2705 **User-Friendly Design**\n",
        "- **No Context Passing** - `project.graph.operation()` instead of `backend.graph.operation(project, ...)`\n",
        "- **Automatic Persistence** - Changes immediately saved to disk\n",
        "- **Type Safety** - Full Pydantic model validation\n",
        "- **Clean Architecture** - Project wrapper with lazy-loaded graph property\n",
        "\n",
        "**Next Steps:**\n",
        "- Build complex computational workflows with the graph API\n",
        "- Integrate with simulation runners (coming soon)  \n",
        "- Connect to cloud APIs (API mode)\n",
        "- Scale to distributed computing environments"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
